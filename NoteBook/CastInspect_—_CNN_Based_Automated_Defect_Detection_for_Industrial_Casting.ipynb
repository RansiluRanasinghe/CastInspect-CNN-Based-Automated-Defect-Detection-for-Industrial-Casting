{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "_sWUY4BiWFh4"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Loading The Data"
      ],
      "metadata": {
        "id": "exhD6fv1WxZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"ravirajsinh45/real-life-industrial-dataset-of-casting-product\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LE8WjT8RWHuE",
        "outputId": "1d469586-c965-482f-9ae0-5d20e0c42a52"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'real-life-industrial-dataset-of-casting-product' dataset.\n",
            "Path to dataset files: /kaggle/input/real-life-industrial-dataset-of-casting-product\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_dataset = \"/root/.cache/kagglehub/datasets/ravirajsinh45/real-life-industrial-dataset-of-casting-product/versions/2\"\n",
        "\n",
        "os.listdir(path_to_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMbR9jN8XEqR",
        "outputId": "68042835-2166-451f-9cba-ce04b2bdf947"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['casting_512x512', 'casting_data']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(os.path.join(path_to_dataset, \"casting_data/casting_data\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5WiDt_ZXIwT",
        "outputId": "03a2499d-28f3-468a-b520-912916763110"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train', 'test']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Deviding into the Train and Test\n",
        "\n",
        "The dataset was already dived into the Train and Test data in separate directories. Therefore, it is easy to use"
      ],
      "metadata": {
        "id": "-KhnAFdQZvVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_DIR = os.path.join(path_to_dataset, \"casting_data/casting_data\")\n",
        "\n",
        "TRAIN_DIR = os.path.join(BASE_DIR, \"train\")\n",
        "TEST_DIR = os.path.join(BASE_DIR, \"test\")"
      ],
      "metadata": {
        "id": "zcV1A4v3Xlih"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = (300, 300)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    TRAIN_DIR,\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    labels = \"inferred\",\n",
        "    label_mode = \"binary\",\n",
        "    color_mode = \"grayscale\"\n",
        ")\n",
        "\n",
        "test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    TEST_DIR,\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    labels = \"inferred\",\n",
        "    label_mode = \"binary\",\n",
        "    color_mode = \"grayscale\"\n",
        "    )"
      ],
      "metadata": {
        "id": "p_GTan-5Zm_B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41bd77d3-9506-4503-ca30-5d59deee060d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6633 files belonging to 2 classes.\n",
            "Found 715 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SHUFFLE_BUFFER_SIZE = 1000\n",
        "PREFETCH_BUFFFER_SIZE = tf.data.AUTOTUNE\n",
        "\n",
        "train_dataset_final = (train_dataset\n",
        "    .cache()\n",
        "    .shuffle(SHUFFLE_BUFFER_SIZE)\n",
        "    .prefetch(PREFETCH_BUFFFER_SIZE)\n",
        ")\n",
        "\n",
        "test_dataset_final = (test_dataset\n",
        "    .cache()\n",
        "    .prefetch(PREFETCH_BUFFFER_SIZE)\n",
        ")"
      ],
      "metadata": {
        "id": "Z8lY_X2bb_Rb"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tgCdzu-Udh7J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}